{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/workspace/javeyqiu/miniconda/envs/sd-xl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Memory Usage:\n",
      "  Used Memory: 17.50 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 0.00 GB\n",
      "GPU 0 Memory Usage:\n",
      "  Total Memory: 14.58 GB\n",
      "  Free Memory: 6.96 GB\n",
      "  Used Memory: 7.62 GB\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, AutoencoderKL, ControlNetModel, StableDiffusionXLControlNetPipeline\n",
    "import torch\n",
    "from time import perf_counter\n",
    "from safetensors.torch import load_file, save_file\n",
    "from safetensors import safe_open\n",
    "import psutil\n",
    "import gc\n",
    "import os\n",
    "\n",
    "def preload_safetensors_to_cpu(safetensors_path):\n",
    "    # 使用 safetensors 库读取权重到 CPU 内存\n",
    "    weights = load_file(safetensors_path, device=\"cpu\")\n",
    "    return weights\n",
    "\n",
    "def get_device_memory_usage(device=0):\n",
    "    # 获取 GPU 剩余显存信息\n",
    "    free_memory, total_memory = torch.cuda.mem_get_info(device)\n",
    "    free_memory_gb = free_memory / (1024 ** 3)  # 转换为 GB\n",
    "    total_memory_gb = total_memory / (1024 ** 3)  # 转换为 GB\n",
    "    used_memory_gb = total_memory_gb - free_memory_gb\n",
    "\n",
    "    print(f\"GPU {device} Memory Usage:\")\n",
    "    print(f\"  Total Memory: {total_memory_gb:.2f} GB\")\n",
    "    print(f\"  Free Memory: {free_memory_gb:.2f} GB\")\n",
    "    print(f\"  Used Memory: {used_memory_gb:.2f} GB\")\n",
    "\n",
    "def get_cpu_memory_usage():\n",
    "    # 获取 CPU 内存使用情况\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    cpu_memory_used = memory_info.used / (1024 ** 3)  # 转换为 GB\n",
    "    cpu_memory_total = memory_info.total / (1024 ** 3)  # 转换为 GB\n",
    "    cpu_memory_free = memory_info.available / (1024 ** 3)  # 转换为 GB\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss / (1024 ** 3)  # 转换为 GB\n",
    "\n",
    "    print(\"CPU Memory Usage:\")\n",
    "    # print(f\"  Total Memory: {cpu_memory_total:.2f} GB\")\n",
    "    print(f\"  Used Memory: {cpu_memory_used:.2f} GB\")\n",
    "    # print(f\"  Free Memory: {cpu_memory_free:.2f} GB\")\n",
    "    # print(f\"  RSS Memory': {mem:.2f} GB\")\n",
    "\n",
    "def get_gpu_memory_usage():\n",
    "    # 获取 GPU 显存使用情况\n",
    "    gpu_memory_allocated = torch.cuda.memory_allocated() / (1024 ** 3)  # 转换为 GB\n",
    "    gpu_memory_reserved = torch.cuda.memory_reserved() / (1024 ** 3)  # 转换为 GB\n",
    "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # 转换为 GB\n",
    "\n",
    "    print(\"GPU Memory Usage:\")\n",
    "    # print(f\"  Total Memory: {gpu_memory_total:.2f} GB\")\n",
    "    # print(f\"  Allocated Memory: {gpu_memory_allocated:.2f} GB\")\n",
    "    print(f\"  Reserved Memory: {gpu_memory_reserved:.2f} GB\")\n",
    "\n",
    "# Example usage\n",
    "get_cpu_memory_usage()\n",
    "get_gpu_memory_usage()\n",
    "get_device_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 清理 GPU 内存缓存\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载一个 SD-XL 基座模型 所需时间为:  3.2940734419971704 s\n",
      "memory allocated: (6.087009429931641, 6.575650691986084, 14.58062744140625)\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"madebyollin/sdxl-vae-fp16-fix\", \n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    ").to(\"cuda\")\n",
    "pipe = DiffusionPipeline.from_pretrained(\"/data1/workspace/javeyqiu/models/stable-diffusion-xl-base-1.0\", \n",
    "                                         torch_dtype=torch.float16, \n",
    "                                         vae=vae,\n",
    "                                         use_safetensors=True, \n",
    "                                         variant=\"fp16\").to(\"cuda\")\n",
    "endtime = perf_counter()-start\n",
    "print(\"加载一个 SD-XL 基座模型 所需时间为: \", endtime, \"s\") \n",
    "get_cpu_memory_usage()\n",
    "get_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "controlnet_path = \"/data1/workspace/javeyqiu/models/huggingface/hub/models--diffusers--controlnet-depth-sdxl-1.0/snapshots/17bb97973f29801224cd66f192c5ffacf82648b4/diffusion_pytorch_model.fp16.safetensors\"\n",
    "\n",
    "controlnet_depth =ControlNetModel.from_single_file(controlnet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从硬盘读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Used Memory: 6.03 GB\n",
      "  RSS Memory': 0.75 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.7664242559112608 s\n",
      "  Used Memory: 8.28 GB\n",
      "  RSS Memory': 3.00 GB\n",
      "  Used Memory: 6.10 GB\n",
      "  RSS Memory': 0.82 GB\n"
     ]
    }
   ],
   "source": [
    "# for i in range(100):\n",
    "start = perf_counter()\n",
    "controlnet_depth = ControlNetModel.from_pretrained(\n",
    "    \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    # low_cpu_mem_usage=True,\n",
    "    # device_map=0,\n",
    "    cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    ").to(\"cuda\")\n",
    "get_cpu_memory_usage()\n",
    "controlnet_depth = controlnet_depth.to('cpu')\n",
    "# pipe_depth = StableDiffusionXLControlNetPipeline.from_pipe(\n",
    "#     pipe,\n",
    "#     controlnet=controlnet_depth,\n",
    "# )\n",
    "endtime = perf_counter()-start\n",
    "print(\"增加一个 controlnet pipe所需时间为: \", endtime, \"s\")\n",
    "get_cpu_memory_usage()\n",
    "\n",
    "del controlnet_depth\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "get_cpu_memory_usage()\n",
    "    # get_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Memory Usage:\n",
      "  Used Memory: 6.92 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 2.47 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 7.79 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 4.92 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 8.66 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 7.37 GB\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "gpu_cache = OrderedDict()\n",
    "cpu_cache = OrderedDict()\n",
    "for i in range(3):\n",
    "    controlnet_depth = ControlNetModel.from_pretrained(\n",
    "        \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "        variant=\"fp16\",\n",
    "        use_safetensors=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    "    ).to(\"cuda\")\n",
    "    # controlnet_depth = torch.load('./stable-diffusion-xl-base-1.0/controlnet_depth.bin').to(\"cuda\")\n",
    "    gpu_cache[f'diffusers/controlnet-depth-sdxl-1.0-{i}'] = controlnet_depth\n",
    "    \n",
    "    get_cpu_memory_usage()\n",
    "    get_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Memory Usage:\n",
      "  Used Memory: 11.03 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.81 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 13.48 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.81 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 15.87 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.84 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 18.23 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.84 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 20.65 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.87 GB\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 23.06 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.87 GB\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    controlnet_depth = ControlNetModel.from_pretrained(\n",
    "        \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "        variant=\"fp16\",\n",
    "        use_safetensors=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    "    ).to(\"cuda\")\n",
    "    # controlnet_depth = torch.load('./stable-diffusion-xl-base-1.0/controlnet_depth.bin').to(\"cuda\")\n",
    "    gpu_cache[f'diffusers/controlnet-depth-sdxl-1.0-{i}'] = controlnet_depth\n",
    "\n",
    "    model_name, model = gpu_cache.popitem(last=False)\n",
    "    model.to('cpu')\n",
    "    cpu_cache[model_name] = model\n",
    "    get_cpu_memory_usage()\n",
    "    get_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加一个 controlnet pipe所需时间为:  1.1605215673334897 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.02 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.1453118841163814 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.02 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.1303139389492571 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.02 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.1489184750244021 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.02 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.2040403131395578 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.23 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.2347728172317147 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.58 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.1448842212557793 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.61 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.242498458828777 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.97 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.1596143133938313 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.98 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n",
      "增加一个 controlnet pipe所需时间为:  1.1395434052683413 s\n",
      "CPU Memory Usage:\n",
      "  Used Memory: 26.97 GB\n",
      "GPU Memory Usage:\n",
      "  Reserved Memory: 9.89 GB\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 30):\n",
    "    start = perf_counter()\n",
    "    # controlnet_depth = ControlNetModel.from_pretrained(\n",
    "    #     \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "    #     variant=\"fp16\",\n",
    "    #     use_safetensors=True,\n",
    "    #     torch_dtype=torch.float16,\n",
    "    #     cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    "    # ).to(\"cuda\")\n",
    "    controlnet_depth = torch.load('./stable-diffusion-xl-base-1.0/controlnet_depth.bin').to(\"cuda\")\n",
    "    gpu_cache[f'diffusers/controlnet-depth-sdxl-1.0-{i}'] = controlnet_depth\n",
    "\n",
    "    model_name, model = gpu_cache.popitem(last=False)\n",
    "    model.to('cpu')\n",
    "    cpu_cache[model_name] = model\n",
    "\n",
    "    _, model_cpu = cpu_cache.popitem(last=False)\n",
    "    del model_cpu\n",
    "    gc.collect()\n",
    "    \n",
    "    endtime = perf_counter()-start\n",
    "    print(\"增加一个 controlnet pipe所需时间为: \", endtime, \"s\")\n",
    "    get_cpu_memory_usage()\n",
    "    get_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(controlnet_depth, './stable-diffusion-xl-base-1.0/controlnet_depth.bin')\n",
    "controlnet_depth = torch.load('./stable-diffusion-xl-base-1.0/controlnet_depth.bin').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Memory Usage:\n",
      "  Total Memory: 62.55 GB\n",
      "  Used Memory: 10.63 GB\n",
      "  Free Memory: 50.81 GB\n",
      "GPU Memory Usage:\n",
      "  Total Memory: 14.58 GB\n",
      "  Allocated Memory: 2.36 GB\n",
      "  Reserved Memory: 2.56 GB\n"
     ]
    }
   ],
   "source": [
    "get_cpu_memory_usage()\n",
    "get_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    controlnet_depth = ControlNetModel.from_pretrained(\n",
    "        \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "        variant=\"fp16\",\n",
    "        use_safetensors=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    "    ).cuda()\n",
    "    del controlnet_depth\n",
    "    gc.collect()\n",
    "    get_cpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 清理 GPU 内存缓存\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从内存读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet_depth = ControlNetModel.from_pretrained(\n",
    "    \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub'\n",
    ").to(\"cuda\")\n",
    "\n",
    "controlnet_depth_path = \"/data1/workspace/javeyqiu/models/huggingface/hub/models--diffusers--controlnet-depth-sdxl-1.0/snapshots/17bb97973f29801224cd66f192c5ffacf82648b4/diffusion_pytorch_model.fp16.safetensors\"\n",
    "controlnet_depth_weights = preload_safetensors_to_cpu(controlnet_depth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_cache = {'depth': controlnet_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加一个 controlnet pipe所需时间为:  0.2635579979978502 s\n",
      "memory allocated: (8.458267211914062, 8.953990459442139, 14.58062744140625)\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "# controlnet_depth.load_state_dict(controlnet_depth_weights)\n",
    "pipe_depth = StableDiffusionXLControlNetPipeline.from_pipe(\n",
    "    pipe,\n",
    "    controlnet=gpu_cache['depth'],\n",
    ")\n",
    "endtime = perf_counter()-start\n",
    "print(\"增加一个 controlnet pipe所需时间为: \", endtime, \"s\")\n",
    "print(\"memory allocated: {}\".format(get_memory_usage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更换一个 controlnet pipe所需时间为:  49.76634782506153 s\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "controlnet_canny = ControlNetModel.from_pretrained(\n",
    "    \"diffusers/controlnet-canny-sdxl-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir='/data1/workspace/javeyqiu/models/huggingface/hub',\n",
    ").to(\"cuda\")\n",
    "# controlnet_canny = torch.load('controlnet_canny.pt').to(\"cuda\")\n",
    "gpu_cache['canny'] = controlnet_canny\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pipe(\n",
    "    pipe_depth,\n",
    "    controlnet=gpu_cache['canny'],\n",
    ")\n",
    "\n",
    "endtime = perf_counter()-start\n",
    "print(\"更换一个 controlnet pipe所需时间为: \", endtime, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# 清理 GPU 内存缓存\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd-xl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
